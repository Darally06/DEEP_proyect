[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelos ResNET para determinar la progresi√≥n de la Dementia",
    "section": "",
    "text": "1 MRI - Deep learning solutions fot dementia Disease prediction\nDe acuerdo con la organizaci√≥n mundial de la salud la dementia es un t√©rmino que engloba varias enfermedades que afectan la memoria, el pensamiento y la capacidad para realizar actividades cotidianas. Esta enfermedad empeora con el tiempo, relacionada a condiciones que destruyen las c√©lulas nerviosas y da√±an el cerebro, lo que conduce a al deterioro de funciones cognitivas. La detecci√≥n de esta destrucci√≥n resulta relevante para la salud de los pacientes e influye en las mejoras a su calidad de vida.\nLas im√°genes de resonancias magn√©ticas (RM) tienen un papel en el diagn√≥stico de la demencia, consiste en permitir el estudio de las estructuras cerebrales y c√≥mo cambian con el tiempo. En este sentido, los cambios en el hipocampo, as√≠ como en las regiones frontal y parietal, son marcadores evidentes del progreso de la enfermedad hacia la demencia.\nLa Iniciativa de Neuroimagen de la Enfermedad de Alzheimer (ADNI) es la colecci√≥n m√°s importante y extensa de informaci√≥n relacionada con el Alzheimer, que contiene diferentes tipos de im√°genes, informaci√≥n gen√©tica, informaci√≥n demogr√°fica, pruebas cognitivas y biomarcadores en l√≠quido cefalorraqu√≠deo.\nSe propone t√©cnicas de Deep Learning y Convolutional Neural Networks, para analizar si []",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>MRI - Deep learning solutions fot dementia Disease prediction</span>"
    ]
  },
  {
    "objectID": "1_ETL_IMAGES.html",
    "href": "1_ETL_IMAGES.html",
    "title": "2¬† ETL -IMAGES",
    "section": "",
    "text": "2.1 Im√°genes descargadas\nCode\n# CARACTERISTICAS DE LAS IMAGENES DESCARGADAS\n\n# [Config] Rutas\noutput_dir  = r\"C:\\Users\\usuario\\MRI\\IMAGES_NII\"\n\n# [] Guardar atributos de las im√°genes\nrecords = []\n\nfor root, dirs, files in os.walk(output_dir):\n    for file in files:\n        if file.endswith(\".nii\"):\n            full_path = os.path.normpath(os.path.join(root, file))\n\n            # üß© Extraer ID del sujeto\n            match_id = re.search(r'(\\d{3}_S_\\d{4})', full_path)\n            sujeto_id = match_id.group(1) if match_id else None\n\n            # üóìÔ∏è Extraer fecha del estudio (YYYY-MM-DD)\n            match_fecha = re.search(r'(\\d{4}-\\d{2}-\\d{2})', full_path)\n            fecha = match_fecha.group(1) if match_fecha else None\n\n            # üîë Extraer ID de imagen (ej. I######)\n            match_img = re.search(r'(I\\d+)', full_path)\n            imagen_id = match_img.group(1) if match_img else None\n\n            # Leer metadatos del NIfTI\n            try:\n                img = nib.load(full_path)\n                data = img.get_fdata()\n\n                header = img.header\n                shape = img.shape\n                voxel_size = header.get_zooms()\n                voxel_volume = np.prod(voxel_size)\n                total_volume = voxel_volume*np.prod(shape)\n                datatype = str(header.get_data_dtype())\n                mean_intensity = np.mean(data)\n                std_intensity = np.std(data)\n                orientation = nib.aff2axcodes(img.affine)\n                units = header.get_xyzt_units()\n\n                records.append([\n                    sujeto_id, fecha, imagen_id, \n                    shape, voxel_size, datatype,\n                    voxel_volume, total_volume, \n                    mean_intensity, std_intensity,\n                    orientation, units, full_path\n                ])\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error leyendo {file}: {e}\")\n\ndf_images = pd.DataFrame(records, columns=[\n    \"sujeto_id\", \"fecha_imagen\", \"imagen_id\",\n    \"shape\", \"voxel_size\", \"datatype\",\n    \"voxel_volume_mm3\", \"total_volume\", \n    \"mean_intensity\", \"std_intensity\", \n    \"orientation\", \"units\",\"ruta\"\n])\n\n# Convertir fecha a tipo datetime\ndf_images[\"fecha_imagen\"] = pd.to_datetime(df_images[\"fecha_imagen\"], errors=\"coerce\")\n\nprint(f\"En total {len(df_images)} im√°genes fueron cargadas correctamente.\")\n\n\nEn total 220 im√°genes fueron cargadas correctamente.\nCode\ndf_images.to_csv('../Data/ADNI_Images.csv', index=False)\nCode\n# Archivos sobre im√°genes descargadas\n# -----------------------------------\n\ndescargas = pd.read_csv('../Data/ADNI_Descargas.csv', sep=';')\ndescargas.rename(columns={'Subject':'sujeto_id', 'Acq Date': 'fecha_imagen', 'Image Data ID': 'imagen_id'}, inplace=True)\n\n# Vistas v√°lidas\ndescargas = descargas[\n    (descargas['Visit'] != 'sc') &\n    (descargas['Visit'] != 'bl') &\n    (descargas['Visit'] != 'nv')\n]\n\n# Correci√≥n de fechas\ndescargas['fecha_imagen'] = pd.to_datetime(\n    descargas['fecha_imagen'],\n    errors='coerce'\n)\n\n# Eliminar im√°genes no usadas\ndescargas = descargas.drop(columns=['Group','Modality', 'Type', 'Format', 'Downloaded', 'Description'])\n\nprint(\n    \"Sobre las im√°genes descargadas: \"\n    f\"\\nIm√°genes: {len(descargas)}\"\n    f\"\\nPacientes √∫nicos: {descargas['sujeto_id'].nunique()}\"\n    f\"\\nVistras √∫nicas: {descargas['Visit'].nunique()}, {descargas['Visit'].unique()}\"\n    f\"\\nAtributos: {descargas.columns}\"\n    )\n\n#Image Data ID;Subject;Group;Sex;Age;Visit;Modality;Description;Type;Acq Date;Format;Downloaded\n\n\nSobre las im√°genes descargadas: \nIm√°genes: 246\nPacientes √∫nicos: 54\nVistras √∫nicas: 7, ['m18' 'm36' 'm06' 'm12' 'm24' 'm48' 'm60']\nAtributos: Index(['imagen_id', 'sujeto_id', 'Sex', 'Age', 'Visit', 'fecha_imagen'], dtype='object')\nCode\nadni_images = pd.merge(\n    df_images,\n    descargas,\n    on=['imagen_id', 'sujeto_id', 'fecha_imagen'],\n    how='left'  # o 'left', 'outer', etc.\n)\nprint(\n    \"Sobre los Imagenes + Pacientes: \"\n    f\"\\nIm√°genes: {len(adni_images)}\"\n    f\"\\nPacientes √∫nicos: {adni_images['sujeto_id'].nunique()}\"\n    f\"\\nVistras √∫nicas: {adni_images['Visit'].nunique()}, {adni_images['Visit'].unique()}\"\n    f\"\\nAtributos: {adni_images.columns}\"\n    )\n\n\nSobre los Imagenes + Pacientes: \nIm√°genes: 220\nPacientes √∫nicos: 51\nVistras √∫nicas: 7, ['m18' 'm36' 'm06' 'm24' 'm48' 'm12' 'm60']\nAtributos: Index(['sujeto_id', 'fecha_imagen', 'imagen_id', 'shape', 'voxel_size',\n       'datatype', 'voxel_volume_mm3', 'total_volume', 'mean_intensity',\n       'std_intensity', 'orientation', 'units', 'ruta', 'Sex', 'Age', 'Visit'],\n      dtype='object')\nCode\n# Archivos ADNI pacientes\nadni = pd.read_csv('../Data/ADNI_pacients.csv', sep=';')\nadni.rename(columns = {'VISCODE':'Visit'}, inplace=True)\nadni = adni.drop(columns=['AGE', 'PTGENDER', 'EXAMDATE'])\n\nprint(\n    \"Sobre los atributos de los pacientes: \"\n    f\"\\nIm√°genes: {len(adni)}\"\n    f\"\\nPacientes √∫nicos: {adni['sujeto_id'].nunique()}\"\n    f\"\\nVistras √∫nicas: {adni['Visit'].nunique()}, {adni['Visit'].unique()}\"\n    f\"\\nAtributos: {adni.columns}\"\n    )\n\n\nSobre los atributos de los pacientes: \nIm√°genes: 228\nPacientes √∫nicos: 51\nVistras √∫nicas: 6, ['m06' 'm12' 'm18' 'm24' 'm30' 'm36']\nAtributos: Index(['sujeto_id', 'Visit', 'DX', 'PTEDUCAT', 'APOE4', 'CDRSB', 'MMSE',\n       'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning',\n       'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR', 'Ventricles',\n       'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp',\n       'ICV'],\n      dtype='object')\nCode\nout = pd.merge(\n    adni_images,\n    adni,\n    on=['sujeto_id', 'Visit'],\n    how='left'  # o 'left', 'outer', etc.\n)\nprint(\n    \"Sobre los Imagenes + Pacientes: \"\n    f\"\\nIm√°genes: {len(out)}\"\n    f\"\\nPacientes √∫nicos: {out['sujeto_id'].nunique()}\"\n    f\"\\nVistras √∫nicas: {out['Visit'].nunique()}, {out['Visit'].unique()}\"\n    f\"\\nAtributos: {out.columns}\"\n    )\n\n\nSobre los Imagenes + Pacientes: \nIm√°genes: 220\nPacientes √∫nicos: 51\nVistras √∫nicas: 7, ['m18' 'm36' 'm06' 'm24' 'm48' 'm12' 'm60']\nAtributos: Index(['sujeto_id', 'fecha_imagen', 'imagen_id', 'shape', 'voxel_size',\n       'datatype', 'voxel_volume_mm3', 'total_volume', 'mean_intensity',\n       'std_intensity', 'orientation', 'units', 'ruta', 'Sex', 'Age', 'Visit',\n       'DX', 'PTEDUCAT', 'APOE4', 'CDRSB', 'MMSE', 'ADAS13', 'FAQ',\n       'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR',\n       'TRABSCOR', 'Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal',\n       'Fusiform', 'MidTemp', 'ICV'],\n      dtype='object')\nCode\nout.to_csv('../Data/ANDI_out.csv', index=False)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**ETL -IMAGES**</span>"
    ]
  },
  {
    "objectID": "1_ETL_IMAGES.html#im√°genes-descargadas",
    "href": "1_ETL_IMAGES.html#im√°genes-descargadas",
    "title": "2¬† ETL -IMAGES",
    "section": "",
    "text": "Leer atributos de las im√°genes\n\n\n\n\nCombinar con datos de descarga\n\n\n\n\nCombinar con datos del paciente [BioMarcadores]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**ETL -IMAGES**</span>"
    ]
  },
  {
    "objectID": "1_ETL_IMAGES.html#imputaci√≥n",
    "href": "1_ETL_IMAGES.html#imputaci√≥n",
    "title": "2¬† ETL -IMAGES",
    "section": "2.2 Imputaci√≥n",
    "text": "2.2 Imputaci√≥n\n\nImputaci√≥n de acuerdo al sujeto\n\n\n\nCode\n# IMPUTACI√ìN\ndf_dx = out.copy()\n\n# DIAGN√ìSTIVCO\n# -------------------------------\ndf_dx = df_dx.sort_values([\"sujeto_id\", \"Visit\"])\nmapping_order = {\"CN\": 0, \"MCI\": 1, \"Dementia\": 2}\ndf_dx[\"DX_num\"] = df_dx[\"DX\"].map(mapping_order)\nsujetos_sin_dx = (\n    df_dx.groupby(\"sujeto_id\")[\"DX\"]\n    .apply(lambda x: x.isna().all())\n)\ndf_dx.loc[df_dx[\"sujeto_id\"].isin(sujetos_sin_dx[sujetos_sin_dx].index), \"DX_num\"] = mapping_order[\"MCI\"]\ndf_dx[\"DX_num\"] = df_dx.groupby(\"sujeto_id\")[\"DX_num\"].ffill()\ndf_dx[\"DX_num\"] = df_dx.groupby(\"sujeto_id\")[\"DX_num\"].bfill()\nreverse_mapping = {v: k for k, v in mapping_order.items()}\ndf_dx[\"DX_imputed\"] = df_dx[\"DX_num\"].map(reverse_mapping)\ndf_dx = df_dx.drop(columns=[\"DX_num\"])\n\n# NIVEL EDUCATIVO\n# -------------------------------\nmediana_global = df_dx[\"PTEDUCAT\"].median()\nmediana_sujeto = df_dx.groupby(\"sujeto_id\")[\"PTEDUCAT\"].transform(\"median\")\n# 3. Asignar:\n# - si el sujeto tiene medianas v√°lidas, usarla\n# - si el sujeto no tiene ning√∫n dato, usar la mediana global\ndf_dx[\"PTEDUCAT_imputed\"] = mediana_sujeto.fillna(mediana_sujeto)\ndf_dx[\"Educat\"] = mediana_sujeto.fillna(mediana_global)\n\n# SEXO - VISITA - TARFET\n# -------------------------------\ndf_dx[\"Sexo\"] = df_dx[\"Sex\"].map({\"M\":0, \"F\":1})\ndf_dx[\"Visita\"] =  df_dx['Visit'].str.extract(r'(\\d+)').astype(int)\nmap_dx = { \"MCI\":0, \"Dementia\":1}\ndf_dx[\"is_dementia\"] = df_dx[\"DX_imputed\"].map(map_dx)\n\n# LABEL de progresion\nlabel_por_sujeto = (\n    df_dx\n    .sort_values(['sujeto_id', 'Visita'])\n    .groupby('sujeto_id')['is_dementia']\n    .apply(lambda x: 1 if (x.diff() == 1).any() or (x.iloc[0] == 1) else 0)\n)\ndf_dx['label'] = df_dx['sujeto_id'].map(label_por_sujeto)\n\n\n\nNormalizaci√≥n de BioMarcadores\n\n\n\nCode\n# VARIABLE VOLUM√âTRICAS\ncognitivas = [\n    \"APOE4\", #APOE4 es una variante gen√©tica de la apolipoprote√≠na E\n    \"CDRSB\", #\"Suma de cajas del Clinical Dementia Rating (CDR); mide la severidad de la demencia.\",\n    \"MMSE\", #\"Mini-Mental State Examination; evaluaci√≥n global del estado cognitivo (m√°x. 30 puntos).\",\n    \"ADAS13\", #\"Alzheimer‚Äôs Disease Assessment Scale ‚Äì 13 √≠tems; mide deterioro cognitivo en Alzheimer.\",\n    \"FAQ\", #\"Functional Activities Questionnaire; eval√∫a la capacidad funcional en actividades diarias.\",\n    \"RAVLT_immediate\", # \"Puntuaci√≥n inmediata en la prueba verbal de aprendizaje (Rey Auditory Verbal Learning Test).\",\n    \"RAVLT_learning\", # \"Puntuaci√≥n de aprendizaje acumulado en RAVLT; mide retenci√≥n verbal.\",\n    \"RAVLT_forgetting\", # \"√çndice de olvido en RAVLT; diferencia entre aprendizaje y recuerdo tard√≠o.\",\n    \"DIGITSCOR\", #\"Digit Span Score; mide memoria de trabajo y atenci√≥n mediante secuencias num√©ricas.\",\n    \"TRABSCOR\", # \"Trail Making Test B Score; eval√∫a funci√≥n ejecutiva y flexibilidad cognitiva.\",\n]\nvolumen = [\n    \"Ventricles\", # \"Volumen de los ventr√≠culos cerebrales; puede indicar atrofia cerebral.\",\n    \"Hippocampus\", # \"Volumen del hipocampo; clave en memoria y afectado en Alzheimer.\",\n    \"WholeBrain\", # \"Volumen total del cerebro; √∫til para evaluar atrofia global.\",\n    \"Entorhinal\", # \"Volumen de la corteza entorrinal; regi√≥n afectada tempranamente en Alzheimer.\",\n    \"Fusiform\", #\"Volumen del giro fusiforme; relacionado con reconocimiento visual.\",\n    \"MidTemp\", # \"Volumen del l√≥bulo temporal medio; implicado en memoria y procesamiento auditivo.\",\n    \"ICV\", #\"Volumen intracraneal total; usado para normalizar medidas volum√©tricas.\"\n]\n\n\n\n\nCode\n# NORMALIZAR\ndef imputar_y_normalizar(df, variables, nombre_grupo):\n   \n    print('-'*50)\n    # Filtrar solo variables num√©ricas v√°lidas\n    variables_num = [v for v in variables if v in df.columns and df[v].dtype.kind in \"iufc\"]\n    print(f\"Variables num√©ricas para imputaci√≥n ({nombre_grupo}):\\n{variables_num}\")\n\n    # Subset de datos\n    datos = df[variables_num].copy()\n\n    # Imputaci√≥n multivariada\n    # Modelo bayesiano iterativo para predecir valores faltantes en funci√≥n de las dem√°s variables.\n    imputer = IterativeImputer(random_state=42, max_iter=20, sample_posterior=True)\n    datos_imputados = imputer.fit_transform(datos)\n\n    # Convertir a DataFrame imputado\n    df_imputado = pd.DataFrame(datos_imputados, columns=variables_num, index=df.index)\n\n    # Reemplazar en el DataFrame original\n    for v in variables_num:\n        df[v] = df_imputado[v]\n\n    print(\"‚úÖ Imputaci√≥n completada.\")\n\n    # Normalizaci√≥n z-score\n    scaler = StandardScaler()\n    df_std = pd.DataFrame(\n        scaler.fit_transform(df[variables_num]),\n        columns=[v + \"_std\" for v in variables_num],\n        index=df.index\n    )\n\n    # Concatenar al DataFrame original\n    df = pd.concat([df, df_std], axis=1)\n\n    return df\n\nprint('Imputaci√≥n')\ndf_dx = imputar_y_normalizar(df_dx, cognitivas, \"cognitivas\")\ndf_dx = imputar_y_normalizar(df_dx, volumen, \"volumen\")\n\n\nImputaci√≥n\n--------------------------------------------------\nVariables num√©ricas para imputaci√≥n (cognitivas):\n['APOE4', 'CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n‚úÖ Imputaci√≥n completada.\n--------------------------------------------------\nVariables num√©ricas para imputaci√≥n (volumen):\n['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n‚úÖ Imputaci√≥n completada.\n\n\n\nDatos Tabulares para el modelo\n\n\n\nCode\ncolumnas = [\n    'sujeto_id','label','is_dementia', 'Visita', 'Age', 'Sexo', 'Educat',\n    'APOE4_std', 'CDRSB_std','MMSE_std', 'ADAS13_std', 'FAQ_std', \n    'RAVLT_immediate_std','RAVLT_learning_std', 'RAVLT_forgetting_std', \n    'DIGITSCOR_std', 'TRABSCOR_std', 'Ventricles_std', 'Hippocampus_std', \n    'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std', 'ICV_std'\n]\n\ndf_tab = df_dx[columnas]\n\n\n\n\nCode\ndf_tab.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 220 entries, 47 to 199\nData columns (total 24 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   sujeto_id             220 non-null    object \n 1   label                 220 non-null    int64  \n 2   is_dementia           220 non-null    int64  \n 3   Visita                220 non-null    int64  \n 4   Age                   220 non-null    int64  \n 5   Sexo                  220 non-null    int64  \n 6   Educat                220 non-null    float64\n 7   APOE4_std             220 non-null    float64\n 8   CDRSB_std             220 non-null    float64\n 9   MMSE_std              220 non-null    float64\n 10  ADAS13_std            220 non-null    float64\n 11  FAQ_std               220 non-null    float64\n 12  RAVLT_immediate_std   220 non-null    float64\n 13  RAVLT_learning_std    220 non-null    float64\n 14  RAVLT_forgetting_std  220 non-null    float64\n 15  DIGITSCOR_std         220 non-null    float64\n 16  TRABSCOR_std          220 non-null    float64\n 17  Ventricles_std        220 non-null    float64\n 18  Hippocampus_std       220 non-null    float64\n 19  WholeBrain_std        220 non-null    float64\n 20  Entorhinal_std        220 non-null    float64\n 21  Fusiform_std          220 non-null    float64\n 22  MidTemp_std           220 non-null    float64\n 23  ICV_std               220 non-null    float64\ndtypes: float64(18), int64(5), object(1)\nmemory usage: 43.0+ KB\n\n\n\n\nCode\ndf_tab.to_csv('../Data/TABULAR.csv', index=False)\n\n\n\nDistribuci√≥n de clases: Progresi√≥n de casos\n\n\n\nCode\n# [] Balance de clases\nprint(\"\\n Distribuci√≥n de la variable objetivo:\")\ndisplay(df_tab[\"label\"].value_counts(normalize=True).mul(100).round(2).to_frame())\ndf_tab[\"label\"].value_counts().plot(kind=\"bar\", title=\"Distribuci√≥n de progresi√≥n\")\n\n# [Test] Z-test para comparar proporciones\ncounts = [df_tab[\"label\"].value_counts()[1],\n          df_tab[\"label\"].value_counts()[0]]\nnobs = [sum(counts), sum(counts)]\nstat, pval = proportions_ztest(counts, nobs)\nprint(f\"\\nPrueba Z-test: Z = {stat:.2f}, p-value = {pval:.4f}\")\n\n\n\n Distribuci√≥n de la variable objetivo:\n\n\n\n\n\n\n\n\n\nproportion\n\n\nlabel\n\n\n\n\n\n0\n59.09\n\n\n1\n40.91\n\n\n\n\n\n\n\n\nPrueba Z-test: Z = -3.81, p-value = 0.0001",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**ETL -IMAGES**</span>"
    ]
  },
  {
    "objectID": "1_ETL_IMAGES.html#estandarizaci√≥n-de-las-im√°genes",
    "href": "1_ETL_IMAGES.html#estandarizaci√≥n-de-las-im√°genes",
    "title": "2¬† ETL -IMAGES",
    "section": "2.3 Estandarizaci√≥n de las im√°genes",
    "text": "2.3 Estandarizaci√≥n de las im√°genes\nLas im√°genes fueron procesadas siguiendo un pipeline estandarizado orientado a:\n\nReorientaci√≥n al sistema anat√≥mico RAS.\nResampleo a una resoluci√≥n isotr√≥pica de 1.0 mm.\nRedimensionamiento a un shape uniforme de 160√ó192√ó192 voxeles.\nNormalizaci√≥n de intensidades mediante Z‚Äêscore.\nExportaci√≥n a formato NumPy (.npy) para uso en modelos 3D.\n\n\n\nCode\n# Medidas m√°s comunes\ndisplay(out['orientation'].value_counts().to_frame())\ndisplay(out['shape'].value_counts().to_frame().head(3))\ndisplay(out['voxel_size'].value_counts().to_frame().head(3))\n\n\n\n\n\n\n\n\n\ncount\n\n\norientation\n\n\n\n\n\n(R, A, S)\n192\n\n\n(P, S, R)\n28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\nshape\n\n\n\n\n\n(166, 256, 256)\n79\n\n\n(160, 192, 192)\n77\n\n\n(180, 256, 256)\n25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\nvoxel_size\n\n\n\n\n\n(1.2, 0.9375, 0.9375)\n97\n\n\n(1.2, 1.25, 1.25)\n75\n\n\n(0.9375, 0.9375, 1.2)\n27\n\n\n\n\n\n\n\n\n\nCode\nimport shutil\n\ndef preprocess_mri_folder(\n        BASE_DIR  = Path(r\"C:\\Users\\usuario\\MRI\\IMAGES_NII\"),\n        output_folder=r\"C:\\Users\\usuario\\MRI\\IMAGES_npy\",\n        target_shape=(160,192,192),\n        target_spacing=(1.0,1.0,1.0)\n    ):\n    \n    if os.path.exists(output_folder):\n        print(\"üßπ Limpiando carpeta de salida...\")\n        shutil.rmtree(output_folder)\n    os.makedirs(output_folder, exist_ok=True)\n\n    # Encuentra TODOS los .nii y .nii.gz dentro de todas las carpetas\n    nii_files = list(BASE_DIR.rglob(\"*.nii\")) + list(BASE_DIR.rglob(\"*.nii.gz\"))\n\n    print(f\"Total im√°genes encontradas: {len(nii_files)}\")\n\n    for fname in tqdm(nii_files, desc=\"Procesando MRI\", unit=\"img\"):\n        #print(f\"\\nProcesando: {fname}\")\n\n        # ----------------------\n        # 1) Cargar imagen y orientar a RAS\n        # ----------------------\n        img = sitk.ReadImage(os.path.join(BASE_DIR, fname))\n        img = sitk.DICOMOrient(img, \"RAS\")\n\n        # ----------------------\n        # 2) Resamplear a voxel 1.0 mm\n        # ----------------------\n        original_spacing = img.GetSpacing()\n        original_size = img.GetSize()\n\n        new_size = [\n            int(round(original_size[i] * (original_spacing[i] / target_spacing[i])))\n            for i in range(3)\n        ]\n\n        resampler = sitk.ResampleImageFilter()\n        resampler.SetInterpolator(sitk.sitkLinear)\n        resampler.SetOutputSpacing(target_spacing)\n        resampler.SetSize(new_size)\n        resampler.SetOutputDirection(img.GetDirection())\n        resampler.SetOutputOrigin(img.GetOrigin())\n\n        img_resampled = resampler.Execute(img)\n\n        # Convertir a numpy\n        arr = sitk.GetArrayFromImage(img_resampled)  # (D,H,W)\n\n        # ----------------------\n        # 3) Ajustar tama√±o a (160,192,192)\n        #    ‚Äî Crop o pad autom√°tico\n        # ----------------------\n        def resize_to_shape(volume, target):\n            out = np.zeros(target, dtype=volume.dtype)\n            \n            # c√°lculo de offsets\n            d, h, w = volume.shape\n            td, th, tw = target\n            \n            # l√≠mites\n            d0 = max((td - d)//2, 0); d1 = d0 + min(d, td)\n            h0 = max((th - h)//2, 0); h1 = h0 + min(h, th)\n            w0 = max((tw - w)//2, 0); w1 = w0 + min(w, tw)\n            \n            vd0 = max((d - td)//2, 0); vd1 = vd0 + min(d, td)\n            vh0 = max((h - th)//2, 0); vh1 = vh0 + min(h, th)\n            vw0 = max((w - tw)//2, 0); vw1 = vw0 + min(w, tw)\n            \n            out[d0:d1, h0:h1, w0:w1] = volume[vd0:vd1, vh0:vh1, vw0:vw1]\n            return out\n\n        arr = resize_to_shape(arr, target_shape)\n\n        # ----------------------\n        # 4) Normalizar intensidad (z-score)\n        # ----------------------\n        arr = arr.astype(np.float32)\n        m = np.mean(arr)\n        s = np.std(arr) + 1e-6\n        arr = (arr - m) / s\n\n        # ----------------------\n        # 5) Guardar como .npy\n        # ----------------------\n        \n        subject_id = fname.parents[3].name\n        image_id = fname.parents[0].name\n\n        out_name = f\"{subject_id}_{image_id}.npy\"\n        out_path = os.path.join(output_folder, out_name)\n        \n        np.save(out_path, arr)\n\n        #print(f\"‚úî Guardado: {out_path}\")\n\n    print(\"\\nüéâ Procesamiento completado.\")\n\n\n# Ejecutar\npreprocess_mri_folder()\n\n\nüßπ Limpiando carpeta de salida...\nTotal im√°genes encontradas: 220\n\n\nProcesando MRI: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220/220 [00:46&lt;00:00,  4.70img/s]\n\n\n\nüéâ Procesamiento completado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**ETL -IMAGES**</span>"
    ]
  },
  {
    "objectID": "2_EDA.html",
    "href": "2_EDA.html",
    "title": "3¬† An√°lisis Exploratorio de Datos",
    "section": "",
    "text": "3.1 DATOS TABULARES\nLas im√°genes utilizadas en este estudio provienen de la iniciativa Alzheimer‚Äôs Disease Neuroimaging Initiative (ADNI), un repositorio internacional de neuroim√°genes longitudinales. Se seleccionaron exclusivamente im√°genes estructurales T1‚Äêponderadas (MRI) correspondientes a sujetos con diagn√≥stico deterioro cognitivo leve (MCI) y demencia tipo Alzheimer (AD).\nEl dataset tabular proviene de los datos cl√≠nicos y neuropsicol√≥gicos asociados a las mismas visitas de imagen, conteniendo informaci√≥n sociodemogr√°fica, gen√©tica, diagn√≥stica y volum√©trica (FreeSurfer).\nCode\n# [Config] Rutas\ndf_tab = pd.read_csv(\"../Data/TABULAR.csv\")\ndf_dx = pd.read_csv('../Data/ANDI_out.csv')\nCode\n# Caracteristicas\nprint(\"CARACTER√çSTICAS\\n\")\nprint(\"======================\"\n      f\"\\nüíø Im√°genes: {len(df_tab)}\"\n      f\"\\nüë®‚Äçü¶≥ Cantidad de pacientes: {df_dx['sujeto_id'].nunique()}\"\n      f\"\\n‚è∫Ô∏è Vistas dispobibles: {df_dx['Visit'].nunique()}, en los meses {df_tab['Visita'].unique()}\"\n      \"\\n======================\"\n)\n\n# Progeso de la enfermedad\nlabels_por_sujeto = df_tab.groupby(\"sujeto_id\")[\"label\"].first()\ntabla_1 = pd.DataFrame({\n    \"conteo\": labels_por_sujeto.value_counts(),\n    \"porcentaje\": labels_por_sujeto.value_counts(normalize=True).mul(100).round(2)\n})\ntabla_1.index = tabla_1.index.map({0: \"No progreso\", 1: \"Progreso\"})\ndisplay(tabla_1.style.set_caption(\"Distribuci√≥n del progreso de la enfermedad\"))\n\n# Im√°gnes\ntabla_2 = pd.DataFrame({\n    \"conteo\": df_tab[\"is_dementia\"].value_counts(),\n    \"porcentaje\": df_tab[\"is_dementia\"].value_counts(normalize=True).mul(100).round(2)\n})\ntabla_2.index = tabla_2.index.map({0: \"MCI\", 1: \"Dementia\"})\ndisplay(tabla_2.style.set_caption(\"Distribuci√≥n de im√°genes con Dementia\"))\n\n# Edad\nprint(\"======================\"\n      f\"\\n#Ô∏è‚É£ Edad de los pacientes:\"\n      f\"\\nM√≠n: {df_tab['Age'].min()} | M√°x: {df_tab['Age'].max()} | Mean: {df_tab['Age'].mean().round(2)}\"\n      \"\\n======================\"\n)\n\n# Sexo\nsex = df_tab.groupby(\"sujeto_id\")[\"Sexo\"].first()\ntabla_3 = pd.DataFrame({\n    \"conteo\": sex.value_counts(),\n    \"porcentaje\": sex.value_counts(normalize=True).mul(100).round(2)\n})\ntabla_3.index = tabla_3.index.map({0: \"Masculino\", 1: \"Femenino\"})\ndisplay(tabla_3.style.set_caption(\"Distribuci√≥n del sexo\"))\n\n# Nivel educativo\neducat = {\n    10: \"10 a√±os (b√°sica incompleta)\",\n    12: \"12 a√±os (secundaria completa)\",\n    13: \"13 a√±os (secundaria + 1 a√±o)\",\n    14: \"14 a√±os (preuniversitario)\",\n    16: \"16 a√±os (licenciatura)\",\n    17: \"17 a√±os (posgrado parcial)\",\n    18: \"18 a√±os (maestr√≠a)\",\n    19: \"19 a√±os (posgrado incompleto)\",\n    20: \"20 a√±os (doctorado/profesional)\"\n}\ntabla_4 = pd.DataFrame({\n    \"conteo\": df_tab[\"Educat\"].value_counts(),\n    \"porcentaje\": df_tab[\"Educat\"].value_counts(normalize=True).mul(100).round(2)\n})\ntabla_4.index = tabla_4.index.map(educat)\ndisplay(tabla_4.style.set_caption(\"Distribuci√≥n de nivel educativo\"))\n\n\nCARACTER√çSTICAS\n\n======================\nüíø Im√°genes: 220\nüë®‚Äçü¶≥ Cantidad de pacientes: 51\n‚è∫Ô∏è Vistas dispobibles: 7, en los meses [ 6 12 18 24 36 48 60]\n======================\n\n\n\n\n\n\n\nTable¬†3.1: Distribuci√≥n del progreso de la enfermedad\n\n\n\n\n\n¬†\nconteo\nporcentaje\n\n\nlabel\n¬†\n¬†\n\n\n\n\nNo progreso\n31\n60.780000\n\n\nProgreso\n20\n39.220000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable¬†3.2: Distribuci√≥n de im√°genes con Dementia\n\n\n\n\n\n¬†\nconteo\nporcentaje\n\n\nis_dementia\n¬†\n¬†\n\n\n\n\nMCI\n158\n71.820000\n\n\nDementia\n62\n28.180000\n\n\n\n\n\n\n\n\n======================\n#Ô∏è‚É£ Edad de los pacientes:\nM√≠n: 61 | M√°x: 91 | Mean: 75.79\n======================\n\n\n\n\n\n\n\nTable¬†3.3: Distribuci√≥n del sexo\n\n\n\n\n\n¬†\nconteo\nporcentaje\n\n\nSexo\n¬†\n¬†\n\n\n\n\nMasculino\n38\n74.510000\n\n\nFemenino\n13\n25.490000\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable¬†3.4: Distribuci√≥n de nivel educativo\n\n\n\n\n\n¬†\nconteo\nporcentaje\n\n\nEducat\n¬†\n¬†\n\n\n\n\n16 a√±os (licenciatura)\n62\n28.180000\n\n\n18 a√±os (maestr√≠a)\n53\n24.090000\n\n\n20 a√±os (doctorado/profesional)\n31\n14.090000\n\n\n19 a√±os (posgrado incompleto)\n19\n8.640000\n\n\n12 a√±os (secundaria completa)\n17\n7.730000\n\n\n14 a√±os (preuniversitario)\n14\n6.360000\n\n\n10 a√±os (b√°sica incompleta)\n13\n5.910000\n\n\n17 a√±os (posgrado parcial)\n6\n2.730000\n\n\n13 a√±os (secundaria + 1 a√±o)\n5\n2.270000\nVariables Volum√©tricas\nCode\ndf_tab.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 220 entries, 0 to 219\nData columns (total 24 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   sujeto_id             220 non-null    object \n 1   label                 220 non-null    int64  \n 2   is_dementia           220 non-null    int64  \n 3   Visita                220 non-null    int64  \n 4   Age                   220 non-null    int64  \n 5   Sexo                  220 non-null    int64  \n 6   Educat                220 non-null    float64\n 7   APOE4_std             220 non-null    float64\n 8   CDRSB_std             220 non-null    float64\n 9   MMSE_std              220 non-null    float64\n 10  ADAS13_std            220 non-null    float64\n 11  FAQ_std               220 non-null    float64\n 12  RAVLT_immediate_std   220 non-null    float64\n 13  RAVLT_learning_std    220 non-null    float64\n 14  RAVLT_forgetting_std  220 non-null    float64\n 15  DIGITSCOR_std         220 non-null    float64\n 16  TRABSCOR_std          220 non-null    float64\n 17  Ventricles_std        220 non-null    float64\n 18  Hippocampus_std       220 non-null    float64\n 19  WholeBrain_std        220 non-null    float64\n 20  Entorhinal_std        220 non-null    float64\n 21  Fusiform_std          220 non-null    float64\n 22  MidTemp_std           220 non-null    float64\n 23  ICV_std               220 non-null    float64\ndtypes: float64(18), int64(5), object(1)\nmemory usage: 41.4+ KB\nCode\ndf_tab.columns\n\n\nIndex(['sujeto_id', 'label', 'is_dementia', 'Visita', 'Age', 'Sexo', 'Educat',\n       'APOE4_std', 'CDRSB_std', 'MMSE_std', 'ADAS13_std', 'FAQ_std',\n       'RAVLT_immediate_std', 'RAVLT_learning_std', 'RAVLT_forgetting_std',\n       'DIGITSCOR_std', 'TRABSCOR_std', 'Ventricles_std', 'Hippocampus_std',\n       'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std',\n       'ICV_std'],\n      dtype='object')",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**An√°lisis Exploratorio de Datos**</span>"
    ]
  },
  {
    "objectID": "2_EDA.html#datos-tabulares",
    "href": "2_EDA.html#datos-tabulares",
    "title": "3¬† An√°lisis Exploratorio de Datos",
    "section": "",
    "text": "APOE4 es una variante gen√©tica de la apolipoprote√≠na E ‚ÄúCDRSB‚Äù, #‚ÄúSuma de cajas del Clinical Dementia Rating (CDR); mide la severidad de la demencia.‚Äù,/ ‚ÄúMMSE‚Äù, #‚ÄúMini-Mental State Examination; evaluaci√≥n global del estado cognitivo (m√°x. 30 puntos).‚Äù,/ ‚ÄúADAS13‚Äù, #‚ÄúAlzheimer‚Äôs Disease Assessment Scale ‚Äì 13 √≠tems; mide deterioro cognitivo en Alzheimer.‚Äù, ‚ÄúFAQ‚Äù, #‚ÄúFunctional Activities Questionnaire; eval√∫a la capacidad funcional en actividades diarias.‚Äù, ‚ÄúRAVLT_immediate‚Äù, # ‚ÄúPuntuaci√≥n inmediata en la prueba verbal de aprendizaje (Rey Auditory Verbal Learning Test).‚Äù, ‚ÄúRAVLT_learning‚Äù, # ‚ÄúPuntuaci√≥n de aprendizaje acumulado en RAVLT; mide retenci√≥n verbal.‚Äù, ‚ÄúRAVLT_forgetting‚Äù, # ‚Äú√çndice de olvido en RAVLT; diferencia entre aprendizaje y recuerdo tard√≠o.‚Äù, ‚ÄúDIGITSCOR‚Äù, #‚ÄúDigit Span Score; mide memoria de trabajo y atenci√≥n mediante secuencias num√©ricas.‚Äù, ‚ÄúTRABSCOR‚Äù, # ‚ÄúTrail Making Test B Score; eval√∫a funci√≥n ejecutiva y flexibilidad cognitiva.‚Äù, ] volumen = [ ‚ÄúVentricles‚Äù, # ‚ÄúVolumen de los ventr√≠culos cerebrales; puede indicar atrofia cerebral.‚Äù, ‚ÄúHippocampus‚Äù, # ‚ÄúVolumen del hipocampo; clave en memoria y afectado en Alzheimer.‚Äù, ‚ÄúWholeBrain‚Äù, # ‚ÄúVolumen total del cerebro; √∫til para evaluar atrofia global.‚Äù, ‚ÄúEntorhinal‚Äù, # ‚ÄúVolumen de la corteza entorrinal; regi√≥n afectada tempranamente en Alzheimer.‚Äù, ‚ÄúFusiform‚Äù, #‚ÄúVolumen del giro fusiforme; relacionado con reconocimiento visual.‚Äù, ‚ÄúMidTemp‚Äù, # ‚ÄúVolumen del l√≥bulo temporal medio; implicado en memoria y procesamiento auditivo.‚Äù, ‚ÄúICV‚Äù, #‚ÄúVolumen intracraneal total; usado para normalizar medidas volum√©tricas.‚Äù]\n\n\n\n\n3.1.1 Diagn√≥stico\n\nDisponibilidad de visitas por sujeto\n\n\n\nCode\n# Crear tabla de presencia de visitas por sujeto\n# Asumiendo df tiene columnas: subject_id, Visita\ndf_visitas = df_tab.copy()\ndf_visitas['Presente'] = 1  # Marca cada fila como \"visita existente\"\n\ntabla_visitas = df_visitas.pivot_table(\n    index='sujeto_id',\n    columns='Visita',\n    values='Presente',\n    aggfunc='last',\n    fill_value=0\n)\n# Graficar heatmap\nplt.figure(figsize=(12,8))\nsns.heatmap(tabla_visitas, cmap=\"Blues\", cbar=False, linewidths=0.5, linecolor='lightgray')\nplt.title(\"Disponibilidad de visitas por sujeto\")\nplt.xlabel(\"Visita\")\nplt.ylabel(\"Sujeto\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nA√±os en estudio\n\n\n\nCode\ndf_dx[\"fecha_imagen\"] = pd.to_datetime(df_dx[\"fecha_imagen\"])\ndf_dx[\"a√±o\"] = df_dx[\"fecha_imagen\"].dt.year\ndf_duracion = df_dx.sort_values([\"sujeto_id\", \"fecha_imagen\"]).groupby(\"sujeto_id\").agg(\n    a√±o_inicio=(\"a√±o\", \"first\"),\n    a√±o_final=(\"a√±o\", \"last\")\n).reset_index()\n\ndf_duracion[\"duracion_anios\"] = df_duracion[\"a√±o_final\"] - df_duracion[\"a√±o_inicio\"]\ndisplay(df_duracion[\"duracion_anios\"].value_counts().sort_index().to_frame())\n\ndf_duracion[\"duracion_anios\"].value_counts().sort_index().plot.barh()\nplt.title(\"A√±os en estudio\")\n\n\n\n\n\n\n\n\n\ncount\n\n\nduracion_anios\n\n\n\n\n\n0\n2\n\n\n1\n8\n\n\n2\n11\n\n\n3\n11\n\n\n4\n14\n\n\n5\n5\n\n\n\n\n\n\n\nText(0.5, 1.0, 'A√±os en estudio')\n\n\n\n\n\n\n\n\n\n\nDistribuci√≥n de edad por visita\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\n\nplt.figure(figsize=(12,8))\n\n# Colormap continuo\ncolormap = plt.get_cmap(\"viridis\")\n\n# Normalizamos edades entre 0 y 1 para el colormap\nages = df_tab['Age']\nnorm = plt.Normalize(vmin=ages.min(), vmax=ages.max())\n\nfor sid, grupo in df_tab.groupby('sujeto_id'):\n    color_values = colormap(norm(grupo['Age']))  # color por edad\n    plt.scatter(grupo['Age'], [sid]*len(grupo), c=color_values, s=50)  # puntos\n    plt.plot(grupo['Age'], [sid]*len(grupo), color='gray', alpha=0.3)     # l√≠nea base\n\nplt.xlabel(\"Edad\")\nplt.ylabel(\"Sujeto\")\nplt.title(\"L√≠nea temporal de visitas por sujeto\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(10,6))\nsns.boxplot(data=df_tab, x='Visita', y='Age', palette='viridis', hue='Visita')\nsns.stripplot(data=df_tab, x='Visita', y='Age', color='black', alpha=0.3, jitter=0.2)  # opcional: puntos individuales\n\nplt.title(\"Distribuci√≥n de edades por visita\")\nplt.xlabel(\"Visita\")\nplt.ylabel(\"Edad\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf_tab.columns\n\n\nIndex(['sujeto_id', 'label', 'is_dementia', 'Visita', 'Age', 'Sexo', 'Educat',\n       'APOE4_std', 'CDRSB_std', 'MMSE_std', 'ADAS13_std', 'FAQ_std',\n       'RAVLT_immediate_std', 'RAVLT_learning_std', 'RAVLT_forgetting_std',\n       'DIGITSCOR_std', 'TRABSCOR_std', 'Ventricles_std', 'Hippocampus_std',\n       'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std',\n       'ICV_std'],\n      dtype='object')\n\n\n\n\n3.1.2 Biomarcadores\n\n\nCode\nbiomarcadores = ['APOE4', 'CDRSB', 'MMSE', 'ADAS13', 'FAQ',\n       'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR',\n       'TRABSCOR']\n\n\n\n\nCode\nplt.figure(figsize=(6, 12))\n\nfor i, biom in enumerate(biomarcadores, 1):\n    plt.subplot(len(biomarcadores), 1, i)\n    sns.boxplot(x=df_dx[biom], color='#2E8E7E')\n    plt.title(biom)\n    plt.xlabel(\"\")\nplt.suptitle(\"Distribuci√≥n de Biomarcadores\", fontsize=14)\nplt.figtext(0.02, 0.5, \"Valor real\", ha='center', va='center', rotation='vertical', fontsize=12)\nplt.tight_layout(rect=[0.05, 0, 1, 1])  # deja espacio para el ylabel global\nplt.show()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nbio_std = ['APOE4_std', 'CDRSB_std', 'MMSE_std', 'ADAS13_std', 'FAQ_std',\n       'RAVLT_immediate_std', 'RAVLT_learning_std', 'RAVLT_forgetting_std',\n       'DIGITSCOR_std', 'TRABSCOR_std']\n\n\n\n\nCode\nplt.figure(figsize=(10,8))\nsns.heatmap(df_tab[bio_std].corr(), annot=True, fmt=\".2f\", cmap=\"GnBu\")\nplt.title(\"Matriz de correlaciones de Biomarcadores\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 Vol√∫menes cerbrales\n\n\nCode\nvolumen = ['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal',\n       'Fusiform', 'MidTemp', 'ICV']\n\n\n\n\nCode\nplt.figure(figsize=(6, 12))\n\nfor i, biom in enumerate(volumen, 1):\n    plt.subplot(len(volumen), 1, i)\n    sns.boxplot(x=df_dx[biom], color='#3E0C4A')\n    plt.title(biom)\n    plt.xlabel(\"\")\nplt.suptitle(\"Distribuci√≥n de Vol√∫menes cerebrales\", fontsize=14)\nplt.figtext(0.02, 0.5, \"Valor real\", ha='center', va='center', rotation='vertical', fontsize=12)\nplt.tight_layout(rect=[0.05, 0, 1, 1])  # deja espacio para el ylabel global\nplt.show()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nvolumn_std =[\n    'Ventricles_std', 'Hippocampus_std',\n       'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std',\n       'ICV_std'\n]\n\n\n\n\nCode\nplt.figure(figsize=(10,8))\nsns.heatmap(df_tab[volumn_std].corr(), annot=True, fmt=\".2f\", cmap=\"GnBu\")\nplt.title(\"Matriz de correlaciones Vol√∫menes\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Aplanar columnas\ninfo_volumen.columns = ['sujeto_id'] + [f\"{var}_{stat}\" for var, stat in info_volumen.columns[1:]]\n\n# Convertir a formato largo\ninfo_long = pd.melt(\n    info_volumen,\n    id_vars=\"sujeto_id\",\n    var_name=\"variable_estadistica\",\n    value_name=\"valor\"\n)\n\n# Separar nombre de variable y tipo de estad√≠stico\ninfo_long[[\"variable\", \"estadistica\"]] = info_long[\"variable_estadistica\"].str.rsplit(\"_\", n=1, expand=True)\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\nC:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_34204\\1002387156.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Agrupar por variable y estad√≠stico\ntabla_resumen = info_long.groupby([\"variable\", \"estadistica\"])[\"valor\"].agg([\"min\", \"mean\", \"max\"]).round(2).reset_index()\n# Ordenar por variable y tipo de estad√≠stico\ntabla_resumen = tabla_resumen.sort_values([\"variable\", \"estadistica\"])\n\n# Mostrar\ntabla_resumen\n\n\n\n\n\n\n\n\n\nvariable\nestadistica\nmin\nmean\nmax\n\n\n\n\n0\nEntorhinal\nmax\n2023.00\n3481.71\n5090.0\n\n\n1\nEntorhinal\nmean\n1853.00\n3157.49\n4511.2\n\n\n2\nEntorhinal\nmin\n1608.00\n2832.86\n4215.0\n\n\n3\nFusiform\nmax\n10946.00\n16742.86\n21808.0\n\n\n4\nFusiform\nmean\n10424.33\n16061.54\n20798.8\n\n\n5\nFusiform\nmin\n9860.00\n15365.92\n19972.0\n\n\n6\nHippocampus\nmax\n4087.00\n6431.73\n9396.0\n\n\n7\nHippocampus\nmean\n3717.67\n6205.67\n9251.5\n\n\n8\nHippocampus\nmin\n3471.00\n5997.59\n9102.0\n\n\n9\nICV\nmax\n1325720.00\n1595814.31\n1888900.0\n\n\n10\nICV\nmean\n1320936.67\n1585118.96\n1867338.0\n\n\n11\nICV\nmin\n1315940.00\n1575091.76\n1850260.0\n\n\n12\nMidTemp\nmax\n11241.00\n18991.55\n25678.0\n\n\n13\nMidTemp\nmean\n10291.00\n18319.15\n24870.0\n\n\n14\nMidTemp\nmin\n9341.00\n17627.04\n23970.0\n\n\n15\nVentricles\nmax\n13209.00\n48518.61\n156066.0\n\n\n16\nVentricles\nmean\n12704.00\n45054.87\n146665.4\n\n\n17\nVentricles\nmin\n12346.00\n41663.00\n126585.0\n\n\n18\nWholeBrain\nmax\n777166.00\n1012856.61\n1249300.0\n\n\n19\nWholeBrain\nmean\n771940.33\n994606.37\n1208020.0\n\n\n20\nWholeBrain\nmin\n765255.00\n976903.06\n1188380.0\n\n\n\n\n\n\n\nLas variables de volumen derivadas de im√°genes de resonancia magn√©tica permiten cuantificar la estructura anat√≥mica del cerebro y detectar cambios asociados con la atrofia y el deterioro cognitivo.\nEn general, los vol√∫menes medios observados muestran una distribuci√≥n coherente con las variaciones esperadas entre sujetos y posibles etapas de deterioro. El volumen intracraneal total (ICV) presenta valores promedio cercanos a 1.59 millones de mm¬≥, siendo una medida anat√≥mica estable que se utiliza para normalizar otras variables de volumen.\nEl volumen total cerebral (WholeBrain) muestra valores promedio alrededor del mill√≥n de mm¬≥, mientras que los ventr√≠culos (Ventricles) presentan una alta variabilidad (media ‚âà 47.000 mm¬≥), lo cual es caracter√≠stico de la expansi√≥n ventricular asociada a procesos de atrofia cortical.\nRegiones cr√≠ticas vinculadas con la memoria, como el hipocampo (Hippocampus) y la corteza entorrinal (Entorhinal), presentan vol√∫menes medios de aproximadamente 6.200 mm¬≥ y 3.100 mm¬≥, respectivamente. La reducci√≥n en estas √°reas se considera uno de los primeros indicadores estructurales del Alzheimer.\nPor otro lado, estructuras del l√≥bulo temporal, como el giro fusiforme (Fusiform) y el l√≥bulo temporal medio (MidTemp), presentan vol√∫menes intermedios (entre 15.000 y 18.000 mm¬≥), reflejando su participaci√≥n en procesos de reconocimiento visual y auditivo.\nEn conjunto, los resultados muestran una tendencia esperada de atrofia progresiva, principalmente en regiones temporales y de memoria, mientras que ICV y WholeBrain act√∫an como referencias anat√≥micas estables para la comparaci√≥n entre sujetos y sesiones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**An√°lisis Exploratorio de Datos**</span>"
    ]
  },
  {
    "objectID": "2_EDA.html#evoluci√≥n-del-diagnostico-por-visita",
    "href": "2_EDA.html#evoluci√≥n-del-diagnostico-por-visita",
    "title": "3¬† An√°lisis Exploratorio de Datos",
    "section": "3.2 6. Evoluci√≥n del Diagnostico por Visita",
    "text": "3.2 6. Evoluci√≥n del Diagnostico por Visita\n\n\nCode\ntabla_dx = df_dx.pivot_table(\n    index=\"sujeto_id\",\n    columns=\"Visit\",\n    values=\"DX\",\n    aggfunc=\"first\"  # Asume que hay una sola entrada por sujeto-visita\n).fillna(\"-\") \ntabla_dx\n\n\n\n\n\n\n\n\nVisit\nm06\nm12\nm18\nm24\nm36\n\n\nsujeto_id\n\n\n\n\n\n\n\n\n\n007_S_0101\nMCI\nMCI\nMCI\nDementia\nDementia\n\n\n007_S_0128\nMCI\nMCI\nDementia\n-\n-\n\n\n007_S_0249\nMCI\nDementia\nDementia\nDementia\nDementia\n\n\n013_S_0240\n-\nMCI\nDementia\n-\n-\n\n\n014_S_0169\nMCI\nMCI\nMCI\nMCI\nMCI\n\n\n018_S_0057\nMCI\nMCI\nDementia\nDementia\n-\n\n\n018_S_0087\nMCI\n-\nMCI\n-\n-\n\n\n018_S_0142\nMCI\nMCI\nMCI\n-\n-\n\n\n018_S_0155\nMCI\nMCI\nMCI\nMCI\n-\n\n\n021_S_0141\n-\nDementia\nDementia\nDementia\n-\n\n\n021_S_0231\nMCI\nMCI\nMCI\nDementia\nDementia\n\n\n021_S_0273\nMCI\nMCI\nMCI\nMCI\n-\n\n\n021_S_0276\nMCI\nMCI\n-\nMCI\nMCI\n\n\n022_S_0004\nMCI\nMCI\nMCI\n-\n-\n\n\n023_S_0042\nMCI\nDementia\nDementia\nDementia\nDementia\n\n\n023_S_0126\n-\nMCI\n-\nMCI\nDementia\n\n\n027_S_0116\nMCI\nMCI\nMCI\nMCI\nMCI\n\n\n027_S_0179\n-\nMCI\nDementia\n-\n-\n\n\n027_S_0256\nDementia\nDementia\nDementia\nDementia\nDementia\n\n\n027_S_0307\nMCI\nMCI\n-\nMCI\nMCI\n\n\n032_S_0187\nMCI\nMCI\nMCI\nDementia\n-\n\n\n032_S_0214\nMCI\nMCI\nMCI\nDementia\nDementia\n\n\n035_S_0033\nMCI\n-\nMCI\nMCI\nMCI\n\n\n035_S_0204\nMCI\nDementia\n-\nDementia\n-\n\n\n035_S_0292\n-\n-\nMCI\n-\n-\n\n\n037_S_0150\nMCI\nMCI\nMCI\nMCI\n-\n\n\n041_S_0282\nMCI\nMCI\nMCI\n-\n-\n\n\n067_S_0038\nMCI\nMCI\n-\n-\n-\n\n\n067_S_0077\nMCI\nDementia\nDementia\nDementia\n-\n\n\n067_S_0098\nMCI\nMCI\n-\n-\n-\n\n\n067_S_0176\nMCI\nMCI\n-\nMCI\n-\n\n\n098_S_0160\nMCI\nMCI\nMCI\nMCI\n-\n\n\n098_S_0269\nDementia\nDementia\n-\n-\n-\n\n\n099_S_0051\nMCI\nMCI\nMCI\nMCI\n-\n\n\n099_S_0054\nMCI\nDementia\nDementia\nDementia\n-\n\n\n099_S_0060\nMCI\nMCI\n-\n-\n-\n\n\n099_S_0111\nMCI\nDementia\n-\n-\n-\n\n\n099_S_0291\nMCI\n-\n-\n-\n-\n\n\n100_S_0006\nMCI\nMCI\nMCI\nMCI\n-\n\n\n100_S_0296\n-\n-\nMCI\nMCI\n-\n\n\n123_S_0108\nMCI\n-\nDementia\nDementia\n-\n\n\n128_S_0188\nMCI\n-\n-\n-\n-\n\n\n128_S_0200\nMCI\n-\n-\n-\n-\n\n\n128_S_0225\nMCI\nMCI\nMCI\nMCI\nMCI\n\n\n128_S_0258\nMCI\nMCI\nMCI\n-\n-\n\n\n130_S_0102\nMCI\nMCI\nMCI\n-\n-\n\n\n130_S_0285\nMCI\nMCI\nMCI\nMCI\n-\n\n\n130_S_0289\nMCI\nMCI\n-\n-\n-\n\n\n136_S_0107\nMCI\nMCI\nMCI\nMCI\nMCI\n\n\n136_S_0195\nMCI\nDementia\nDementia\n-\n-\n\n\n\n\n\n\n\n\n3.2.1 Diagnostico Inicial vrs Final\n\n\nCode\ndf_a = df_dx.sort_values([\"sujeto_id\", \"Visit\"]).groupby(\"sujeto_id\").agg(\n    dx_inicio=(\"DX\", \"first\"),\n    dx_final=(\"DX\", \"last\")\n).reset_index()\ntabla_transicion = df_a.groupby([\"dx_inicio\", \"dx_final\"]).size().unstack(fill_value=0)\ntabla_transicion\n\n\n\n\n\n\n\n\ndx_final\nDementia\nMCI\n\n\ndx_inicio\n\n\n\n\n\n\nDementia\n3\n0\n\n\nMCI\n17\n30\n\n\n\n\n\n\n\nEl diagn√≥stico inicial muestra que todos los participantes comenzaron el estudio con deterioro cognitivo leve (MCI). Sin embargo, al finalizar el seguimiento, 22 de ellos progresaron a demencia, mientras que 29 se mantuvieron en la misma condici√≥n. Esto refleja una tendencia esperada en la evoluci√≥n cl√≠nica del MCI, donde una proporci√≥n significativa de pacientes presenta un empeoramiento cognitivo a lo largo del tiempo, mientras que otros permanecen estables.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**An√°lisis Exploratorio de Datos**</span>"
    ]
  }
]