{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2d59f7",
   "metadata": {},
   "source": [
    "# **CNN 2.5D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842dd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Standard Libraries ====\n",
    "import os, time, warnings\n",
    "\n",
    "# ==== Scientific & Data Handling ====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== PyTorch Core ====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ==== ML & Evaluation ====\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# ==== Utilities ====\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Reproducibility ====\n",
    "SEED = 42\n",
    "\n",
    "# ==== Device Handling (DirectML + fallback CPU) ====\n",
    "try:\n",
    "    import torch_directml\n",
    "    DEVICE = torch_directml.device()\n",
    "    print(\"Using DirectML device:\", DEVICE)\n",
    "except Exception as e:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"DirectML no disponible. Usando CPU:\", e)\n",
    "\n",
    "# ==== Warnings ====\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '../Data/Tabular.csv'\n",
    "FOLDER_PATH = r\"C:\\Users\\usuario\\MRI\\IMAGES_npy\"\n",
    "\n",
    "OUTPUT_DIR = \"../Models_Output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes únicos encontrados: {(160, 192, 192)}\n",
      "Total de imágenes: 220\n",
      "Media global promedio: 0.0000\n",
      "Desviación global promedio: 1.0000\n",
      "Size únicos: {5898240}\n"
     ]
    }
   ],
   "source": [
    "# [] Atributos de las imégenes\n",
    "shapes, means, stds, size = [], [], [], []\n",
    "\n",
    "for f in os.listdir(FOLDER_PATH):\n",
    "    if f.endswith(\".npy\"):\n",
    "        img = np.load(os.path.join(FOLDER_PATH, f))\n",
    "        shapes.append(img.shape)\n",
    "        means.append(img.mean())\n",
    "        stds.append(img.std())\n",
    "        size.append(img.size)\n",
    "\n",
    "# Contar shapes únicos\n",
    "shapes_unicos = set(shapes)\n",
    "size_unicos = set(size)\n",
    "print(\"Shapes únicos encontrados:\", shapes_unicos)\n",
    "print(\"Total de imágenes:\", len(shapes))\n",
    "print(f\"Media global promedio: {np.mean(means):.4f}\")\n",
    "print(f\"Desviación global promedio: {np.mean(stds):.4f}\")\n",
    "print(f\"Size únicos: {size_unicos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CSV\n",
    "# ============================\n",
    "df = pd.read_csv(CSV_PATH, dtype={'sujeto_id': str})\n",
    "df = df.dropna(subset=['is_dementia'])\n",
    "\n",
    "df['sujeto_id'] = df['sujeto_id'].astype(str).str.strip()\n",
    "df['imagen_id'] = df['imagen_id'].astype(str).str.strip()\n",
    "\n",
    "# FULL FILE PATH\n",
    "def build_path(row):\n",
    "    filename = f\"{row['sujeto_id']}_{row['imagen_id']}.npy\"\n",
    "    return os.path.join(FOLDER_PATH, filename)\n",
    "\n",
    "df['file_path'] = df.apply(build_path, axis=1)\n",
    "\n",
    "df = df[['file_path', 'sujeto_id', 'is_dementia']].rename(\n",
    "    columns={'is_dementia': 'label'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUCIÓN DE CLASES ===\n",
      "Clase 0 (No Dementia): 158 imágenes - 71.82%\n",
      "Clase 1 (Dementia): 62 imágenes - 28.18%\n",
      "Estadístico Z: -7.1933\n",
      "Valor p: 6.3244e-13\n",
      "\n",
      "Conclusión: Se rechaza H0. La proporción de la Clase 1 (28.18%) es SIGNIFICATIVAMENTE diferente de 50%.\n"
     ]
    }
   ],
   "source": [
    "# 1. Distribución básica de is_dementia\n",
    "\n",
    "class_distribution = df['label'].value_counts().sort_index()\n",
    "print(\"=== DISTRIBUCIÓN DE CLASES ===\")\n",
    "print(f\"Clase 0 (No Dementia): {class_distribution.get(0, 0)} imágenes - {class_distribution.get(0, 0)/len(df)*100:.2f}%\")\n",
    "print(f\"Clase 1 (Dementia): {class_distribution.get(1, 0)} imágenes - {class_distribution.get(1, 0)/len(df)*100:.2f}%\")\n",
    "class_distribution = df['label'].value_counts().sort_index()\n",
    "N = len(df)\n",
    "count_dementia = class_distribution.get(1, 0)\n",
    "expected_proportion = 0.5 \n",
    "z_stat, p_value = proportions_ztest(count=count_dementia, \n",
    "                                    nobs=N, \n",
    "                                    value=expected_proportion, \n",
    "                                    alternative='two-sided')\n",
    "print(f\"Estadístico Z: {z_stat:.4f}\")\n",
    "print(f\"Valor p: {p_value:.4e}\")\n",
    "# Conclusión\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusión: Se rechaza H0. La proporción de la Clase 1 ({count_dementia/N*100:.2f}%) es SIGNIFICATIVAMENTE diferente de {expected_proportion*100:.0f}%.\")\n",
    "else:\n",
    "    print(f\"\\nConclusión: No se rechaza H0. No hay evidencia suficiente para decir que la proporción es diferente de {expected_proportion*100:.0f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f144b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 1] Group stratified split (returns DataFrames)\n",
    "# ---------------------------\n",
    "\n",
    "def group_stratified_split(records):\n",
    "    \"\"\"\n",
    "    Divide los datos en train/val/test respetando:\n",
    "        - Que todas las imágenes de un mismo sujeto estén en un mismo conjunto.\n",
    "        - La distribución de clases (estratificación) por sujeto.\n",
    "\n",
    "    Args:\n",
    "        records (list of dict): Lista de registros (por ejemplo, resultado de df.to_dict(\"records\")).\n",
    "        seed (int): Semilla para reproducibilidad.\n",
    "\n",
    "    Returns:\n",
    "        train_df, val_df, test_df (pd.DataFrame): DataFrames de cada conjunto.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertimos la lista de registros a DataFrame\n",
    "    df_local = pd.DataFrame(records)\n",
    "\n",
    "    # Obtenemos la etiqueta por sujeto: promedio de labels redondeado a entero\n",
    "    subj_lab = df_local.groupby(\"sujeto_id\")[\"label\"].agg(lambda x: int(round(x.mean())))\n",
    "    subjects = subj_lab.index.to_list()   # lista de IDs únicos\n",
    "    y = subj_lab.values                   # etiquetas por sujeto\n",
    "\n",
    "    # Dividir en train (70%) y resto (30%) respetando grupos\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=SEED)\n",
    "    train_idx, rest_idx = next(gss.split(subjects, y, groups=subjects))\n",
    "\n",
    "    train_subj = [subjects[i] for i in train_idx]\n",
    "    rest_subj  = [subjects[i] for i in rest_idx]\n",
    "\n",
    "    # Estratificación para val/test (50%/50% del resto)\n",
    "    rest_labels = [subj_lab[s] for s in rest_subj]\n",
    "    val_subj, test_subj = train_test_split(\n",
    "        rest_subj,\n",
    "        test_size=0.5,\n",
    "        random_state=SEED,\n",
    "        stratify=rest_labels\n",
    "    )\n",
    "\n",
    "    # Función para extraer filas de cada conjunto\n",
    "    def pick(subjects_list):\n",
    "        return df_local[df_local[\"sujeto_id\"].isin(subjects_list)].reset_index(drop=True)\n",
    "\n",
    "    # Retornamos DataFrames\n",
    "    return pick(train_subj), pick(val_subj), pick(test_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dee186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 2] Construcción del DataSet MRI 2.5D\n",
    "# ---------------------------\n",
    "\n",
    "class MRI2p5DDataset(Dataset):\n",
    "    def __init__(self, df, n_slices=32, target_size=(224,224), augment=False):\n",
    "        \"\"\"\n",
    "        df: DataFrame con columnas 'file_path' y 'label'\n",
    "        n_slices: número de cortes a tomar por volumen\n",
    "        target_size: tamaño HxW de las imágenes\n",
    "        augment: aplicar data augmentation\n",
    "        \"\"\"\n",
    "        self.records = df.to_dict(\"records\")\n",
    "        self.n_slices = n_slices\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "\n",
    "        # Transforms\n",
    "        self.augment_tf = T.Compose([\n",
    "            T.RandomRotation(10),\n",
    "            T.RandomResizedCrop(target_size, scale=(0.9,1.0))\n",
    "        ])\n",
    "        self.base_tf = T.Compose([\n",
    "            T.Resize(target_size),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        vol = np.load(rec[\"file_path\"])  # (D,H,W) 3D array, Cortes-Altura-Ancho\n",
    "\n",
    "        # Elegir n_slices uniformemente\n",
    "        D = vol.shape[0]\n",
    "        idxs = np.linspace(0, D-1, self.n_slices).astype(int)\n",
    "        slices = vol[idxs]  # (n_slices,H,W)\n",
    "\n",
    "        # Convertir cada slice a tensor\n",
    "        imgs = []\n",
    "        for s in slices:\n",
    "            # Normalizar a [0,255] y convertir a PIL\n",
    "            s_img = ((s - s.min())/(s.max()-s.min()+1e-6) * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(s_img).convert(\"L\")  # 1 canal\n",
    "            if self.augment:\n",
    "                img = self.augment_tf(img)\n",
    "            img = self.base_tf(img)  # (1,H,W)\n",
    "            imgs.append(img)\n",
    "        \n",
    "        # Apilar slices como canales -> (n_slices,H,W)\n",
    "        input_tensor = torch.cat(imgs, dim=0)\n",
    "        \n",
    "        label = torch.tensor(rec[\"label\"], dtype=torch.float32)\n",
    "        return input_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 3] Modelo CNN 2.5D\n",
    "# ---------------------------\n",
    "\n",
    "class CNN2p5D(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN simple para volúmenes 2.5D: toma n_slices como canales.\n",
    "    Más ligera que ResNet, menos propensa a overfitting.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_slices=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(n_slices, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),         # 112x112\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),         # 56x56\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),         # 28x28\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),         # 14x14\n",
    "        )\n",
    "\n",
    "        # Clasificador final\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80edbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 4] Entrenamiento por epoca y evaluacion\n",
    "# ---------------------------\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()                    # Coloca el modelo en modo entrenamiento\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "    \n",
    "    for X, y in pbar:\n",
    "        X, y = X.to(device), y.to(device)  # Enviar batch a GPU/CPU\n",
    "        optimizer.zero_grad()              # Reiniciar gradientes\n",
    "\n",
    "        logits = model(X)                  # Forward\n",
    "        loss = criterion(logits, y)        # Calcular pérdida\n",
    "        loss.backward()                     # Backpropagation\n",
    "        optimizer.step()                    # Actualizar pesos\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)  # Acumular pérdida ponderada por batch\n",
    "        total += y.size(0)\n",
    "        pbar.set_postfix({\"batch_loss\": loss.item()})  # Mostrar pérdida por batch\n",
    "\n",
    "    return total_loss / total  # Pérdida promedio por sample\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()                       # Coloca el modelo en modo evaluación\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():               # No computa gradientes\n",
    "        for X, y in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            probs = torch.sigmoid(logits)  # Convertir logit a probabilidad\n",
    "            preds = (probs > 0.5).float()  # Umbral 0.5 para clasif binaria\n",
    "\n",
    "            all_preds.append(probs.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    # Concatenar todos los batches\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Métricas\n",
    "    acc = (all_preds.round() == all_labels).float().mean().item()   # Accuracy\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds.round())  # Balanced Accuracy\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)                   # AUC ROC\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    \n",
    "    return acc, bal_acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 5] DataLoaders\n",
    "# ---------------------------\n",
    "def prepare_dataloaders(df, batch_size, n_slices=32, target_size=(224,224)):\n",
    "    records = df.to_dict(\"records\")\n",
    "    train_df, val_df, test_df = group_stratified_split(records)\n",
    "\n",
    "    # Mostrar distribución original\n",
    "    print(\"=== Distribución original en Train ===\")\n",
    "    print(train_df['label'].value_counts())\n",
    "\n",
    "    # Oversampling de clase minoritaria\n",
    "    df_min = train_df[train_df['label'] == 1]\n",
    "    df_maj = train_df[train_df['label'] == 0]\n",
    "\n",
    "    df_min_upsampled = resample(\n",
    "        df_min,\n",
    "        replace=True,\n",
    "        n_samples=len(df_maj),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_df_bal = pd.concat([df_maj, df_min_upsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "    # Mostrar distribución después de oversampling\n",
    "    print(\"=== Distribución después de oversampling en Train ===\")\n",
    "    print(train_df_bal['label'].value_counts())\n",
    "\n",
    "    # Crear datasets\n",
    "    train_dataset = MRI2p5DDataset(train_df_bal,\n",
    "                                   n_slices=n_slices, target_size=target_size, augment=True)\n",
    "    val_dataset   = MRI2p5DDataset(val_df, n_slices=n_slices, target_size=target_size, augment=False)\n",
    "    test_dataset  = MRI2p5DDataset(test_df, n_slices=n_slices, target_size=target_size, augment=False)\n",
    "\n",
    "    # Crear DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Mostrar tamaño de cada loader\n",
    "    print(f\"\\nTrain Loader: {len(train_loader.dataset)} ejemplos, {len(train_loader)} batches\")\n",
    "    print(f\"Validation Loader: {len(val_loader.dataset)} ejemplos, {len(val_loader)} batches\")\n",
    "    print(f\"Test Loader: {len(test_loader.dataset)} ejemplos, {len(test_loader)} batches\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 6] Modulo de entrenamiento\n",
    "# ---------------------------\n",
    "def train_model(\n",
    "        model, train_loader, val_loader, device, \n",
    "        epochs, lr, weight_decay, early_stopping_patience):\n",
    "    \"\"\"\n",
    "    Entrena el modelo y retorna listas de pérdidas y métricas.\n",
    "    \"\"\"\n",
    "    print(f\"\\n⏺️ Entrenando modelo: \\nÉpocas {epochs} | LR-WD {lr}-{ weight_decay} | Patience {early_stopping_patience}\")\n",
    "    pos = 62\n",
    "    neg = 158\n",
    "    pos_weight = torch.tensor(neg / pos)  # 158/62 ~ 2.55\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    train_losses, val_bal_accs, val_aucs = [], [], []\n",
    "    best_bal_acc = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(\"▶️ Start train\")\n",
    "    time_all = time.time()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        time_ep = time.time()\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        time_train = time.time() - time_ep\n",
    "        acc, bal_acc, auc = evaluate(model, val_loader, device)\n",
    "        \n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_bal_accs.append(bal_acc)\n",
    "        val_aucs.append(auc)\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} | TrainLoss={train_loss:.4f} || Validation:  Acc={acc:.4f} | Balance={bal_acc:.4f} | AUC={auc:.4f} || Time: {time_train:.1f}\")\n",
    "\n",
    "        # Scheduler\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        # Early stopping + guardado del mejor modelo\n",
    "        if bal_acc > best_bal_acc:\n",
    "            best_bal_acc = bal_acc\n",
    "            patience_counter = 0\n",
    "            model_path = f\"../Models_Output/model_{epochs}_{ep}_{early_stopping_patience}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\">> Mejor modelo guardado\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\">> Early stopping activado\")\n",
    "                break\n",
    "    \n",
    "    print(f\"Tiempo total de entrenamiento: {(time.time() - time_all)/60:.2f} minutos\")\n",
    "    return train_losses, val_bal_accs, val_aucs, model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PASO 7] Modulo de evaluación final\n",
    "# ---------------------------\n",
    "def evaluate_final(model, test_loader, device, model_path):\n",
    "    \"\"\"\n",
    "    Carga el mejor modelo guardado y devuelve métricas sobre el test set,\n",
    "    incluyendo matriz de confusión y reporte de precision/recall/F1.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    acc = (all_preds == all_labels).float().mean().item()\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"Test Acc={acc:.4f} | Test Balanced Acc={bal_acc:.4f} | Test AUC={auc:.4f}\")\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Reporte de Precision / Recall / F1\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"No Dementia\", \"Dementia\"])\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(report)\n",
    "\n",
    "    return acc, bal_acc, auc, cm, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# MAIN\n",
    "# ---------------------------\n",
    "def main(df, device, EPOCHS, LR, WEIGHT, EARLY, BATCH):\n",
    "    train_loader, val_loader, test_loader = prepare_dataloaders(df, BATCH)\n",
    "\n",
    "    model = CNN2p5D(n_slices=32).to(device)\n",
    "    \n",
    "    train_losses, val_bal_accs, val_aucs, model_path = train_model(\n",
    "        model, train_loader, val_loader, device, \n",
    "        EPOCHS, LR, WEIGHT, EARLY)\n",
    "    # Curvas\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(val_bal_accs, label='Val Balanced Acc')\n",
    "    plt.plot(val_aucs, label='Val AUC')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Score'); plt.legend(); plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluación final\n",
    "    evaluate_final(model, test_loader, device, model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
