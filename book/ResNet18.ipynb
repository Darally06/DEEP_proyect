{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ff18c",
   "metadata": {},
   "source": [
    "# **ResNet18 como modelo base**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b49aa1",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355b2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math, random, time, json, torch_directml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbb90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "DATA_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")\n",
    "LABELS_CSV = r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\"\n",
    "OUTPUT_DIR = \"models_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfc143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: intensity normalization, slice extraction\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def contrast_normalize_volume(vol, pmin=2, pmax=98):     \n",
    "    vmin = np.percentile(vol, pmin)    \n",
    "    vmax = np.percentile(vol, pmax)    \n",
    "    vol = np.clip(vol, vmin, vmax)    \n",
    "    vol = (vol - vmin) / (vmax - vmin + 1e-9)    \n",
    "    return vol.astype(np.float32)\n",
    "\n",
    "def get_central_slices(vol, n_slices=10):  \n",
    "    \"\"\" Extract n central axial slices from a volume shaped.   \"\"\"\n",
    "    D = vol.shape[0]    \n",
    "    center = D // 2    \n",
    "    half = n_slices // 2   \n",
    "    start = max(0, center - half)    \n",
    "    end = min(D, start + n_slices)\n",
    "    slices = vol[start:end]\n",
    "    if slices.shape[0] < n_slices:  # padding si faltan\n",
    "        pad_before = (n_slices - slices.shape[0]) // 2\n",
    "        pad_after = n_slices - slices.shape[0] - pad_before\n",
    "        slices = np.concatenate([\n",
    "            np.repeat(slices[[0]], pad_before, axis=0),\n",
    "            slices,\n",
    "            np.repeat(slices[[-1]], pad_after, axis=0)\n",
    "        ], axis=0)\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: loads one volume per item and returns tensor of shape (n_slices, C, H, W)\n",
    "class MRIVolumeDataset(Dataset):\n",
    "    def __init__(self, records, n_slices=10, target_size=(224,224), transform=None, skull_strip=False):\n",
    "        self.records = records        \n",
    "        self.n_slices = n_slices        \n",
    "        self.target_size = target_size        \n",
    "        self.transform = transform        \n",
    "        self.skull_strip = skull_strip    \n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.records)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        vol = np.load(rec['path'])  # Volumen (160,192,192)\n",
    "\n",
    "        vol = contrast_normalize_volume(vol)\n",
    "        slices = get_central_slices(vol, self.n_slices)\n",
    "\n",
    "        imgs = []\n",
    "        for s in slices:\n",
    "            img = Image.fromarray((s * 255).astype(np.uint8))\n",
    "            img = img.resize(self.target_size)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])(img)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = torch.stack(imgs, dim=0)  # (n_slices, C, H, W)\n",
    "        label = torch.tensor(rec['label'], dtype=torch.float32)\n",
    "        \n",
    "        return imgs, label, rec['sujeto_id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d358e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Clase] Modelo RestNet\n",
    "class ResNetSliceClassifier(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18', pretrained=False, n_slices=10, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.n_slices = n_slices\n",
    "\n",
    "        if backbone_name == 'resnet18':\n",
    "            base = resnet18(weights=None if not pretrained else ResNet18_Weights.DEFAULT)\n",
    "            feat_dim = base.fc.in_features\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo no soportado: {backbone_name}\")\n",
    "        # Secuencia de la red\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(feat_dim, 1)\n",
    "\n",
    "    # Paso forward\n",
    "    def forward(self, x):\n",
    "        B, S, C, H, W = x.shape\n",
    "        x = x.view(B*S, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.global_pool(feats).view(B, S, -1)\n",
    "        agg = feats.mean(dim=1)\n",
    "        out = self.dropout(agg)\n",
    "        logits = self.classifier(out).squeeze(1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_records(data_dir, labels_csv):\n",
    "    labels_df = pd.read_csv(labels_csv, dtype={'sujeto_id': str})\n",
    "    labels_df = labels_df.dropna(subset=['is_dementia']) # Excluir imÃ¡genes sin datos\n",
    "    labels_df['sujeto_id'] = labels_df['sujeto_id'].str.strip()\n",
    "    label_map = dict(zip(labels_df['sujeto_id'], labels_df['is_dementia']))\n",
    "\n",
    "    records = []\n",
    "    for p in glob.glob(os.path.join(data_dir, \"*.npy\")):\n",
    "        subj = os.path.basename(p)[:10].strip()\n",
    "        if subj in label_map:\n",
    "            records.append({\"path\": p, \"sujeto_id\": subj, \"label\": int(label_map[subj])})\n",
    "    return records\n",
    "\n",
    "# DivisiÃ³n estratificada\n",
    "def group_stratified_split(records, train_size=0.7, val_size=0.15, test_size=0.15, seed=42):\n",
    "    df = pd.DataFrame(records)\n",
    "    subj_lab = df.groupby(\"sujeto_id\")[\"label\"].agg(lambda x: int(round(x.mean())))\n",
    "    subjects = subj_lab.index.to_list()\n",
    "    y = subj_lab.values\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    train_idx, rest_idx = next(gss.split(subjects, y, groups=subjects))\n",
    "    train_subj = [subjects[i] for i in train_idx]\n",
    "    rest_subj = [subjects[i] for i in rest_idx]\n",
    "\n",
    "    val_prop = val_size / (val_size + test_size)\n",
    "    val_subj, test_subj = train_test_split(rest_subj, test_size=1 - val_prop, random_state=seed, stratify=[subj_lab[s] for s in rest_subj])\n",
    "\n",
    "    def select_by_subject(subj_list):\n",
    "        return [r for r in records if r[\"sujeto_id\"] in subj_list]\n",
    "\n",
    "    return select_by_subject(train_subj), select_by_subject(val_subj), select_by_subject(test_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d5e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(records):\n",
    "    labels = [r['label'] for r in records]\n",
    "    cnt0 = sum(l == 0 for l in labels)\n",
    "    cnt1 = sum(l == 1 for l in labels)\n",
    "    pos_weight = torch.tensor([cnt0 / (cnt1 + 1e-9)], dtype=torch.float32)\n",
    "    return pos_weight, cnt0, cnt1\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y, _ in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            probs = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            preds.extend((probs >= 0.5).astype(int))\n",
    "            ys.extend(y.cpu().numpy().astype(int))\n",
    "    return balanced_accuracy_score(ys, preds)\n",
    "\n",
    "# Entrenamiento por Ã©pocas\n",
    "def train_one_model(model, train_loader, val_loader, device, pos_weight, lr=1e-4, epochs=10, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_bac = 0\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_bac\": []}\n",
    "    time_1 = time.time()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        val_bac = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {e+1}/{epochs} | Loss {total_loss/len(train_loader):.4f} | Val BAC {val_bac:.4f} | Tiempo {epoch_time/60:.2f} minutos\")\n",
    "        \n",
    "        # Guardar historia\n",
    "        history[\"epoch\"].append(e + 1)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        history[\"val_bac\"].append(val_bac)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_bac > best_bac:\n",
    "            best_bac = val_bac\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping activado en epoch {e+1}\")\n",
    "                break\n",
    "\n",
    "    total_time = time.time() - time_1\n",
    "    print(f\"Entrenamiento completo en {total_time/60:.2f} minutos\")\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5722d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar rendimiento\n",
    "def plot_training_history(history, model_name=\"modelo\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "    plt.plot(history[\"epoch\"], history[\"val_bac\"], label=\"Val Balanced Accuracy\", marker=\"s\")\n",
    "    plt.xlabel(\"Ã‰poca\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"EvoluciÃ³n del entrenamiento - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar imagen\n",
    "    filename = f\"models_output/history_{model_name}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"GrÃ¡fico guardado en: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a11a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dry_run=True):\n",
    "    records = build_records(DATA_DIR, LABELS_CSV)\n",
    "    print(f\"VolÃºmenes encontrados: {len(records)}\")\n",
    "    train_recs, val_recs, test_recs = group_stratified_split(records, seed = SEED)\n",
    "    pos_weight, c0, c1 = compute_class_weights(train_recs)\n",
    "    print(f\"Clases: 0={c0}, 1={c1}, pos_weight={pos_weight.item():.2f}\")\n",
    "    print(f\"Bach {BATCH_SIZE}, slices {N_SLICES}, epocas {EPOCHS}, patience {PATIENCE}\")\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    # Extraer imÃ¡genes\n",
    "    train_ds = MRIVolumeDataset(train_recs, transform=transform)\n",
    "    val_ds = MRIVolumeDataset(val_recs)\n",
    "    test_ds = MRIVolumeDataset(test_recs)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    if dry_run:\n",
    "        X, y, _ = next(iter(train_loader))\n",
    "        print(\"Ejemplo:\", X.shape, y.shape)\n",
    "        return\n",
    "\n",
    "    # Estructura principal\n",
    "    results = []\n",
    "    for backbone in ['resnet18']:\n",
    "        print(f\"\\n=== Entrenando {backbone} ===\")\n",
    "        model = ResNetSliceClassifier(backbone, n_slices=N_SLICES) # type: ignore\n",
    "        trained, history = train_one_model(model, train_loader, val_loader, DEVICE, pos_weight, lr=LR, epochs=EPOCHS, patience=PATIENCE)\n",
    "        test_bac = evaluate_model(trained, test_loader, DEVICE)\n",
    "        results.append((backbone, test_bac))\n",
    "        print(f\"Test BAC ({backbone}): {test_bac:.4f}\")\n",
    "\n",
    "        torch.save(trained.state_dict(), f\"{OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "        print(f\"Modelo guardado: {OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "\n",
    "        plot_training_history(history, model_name=f\"{backbone}_slices{N_SLICES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacb7b4",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a008b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device -> cpu\n"
     ]
    }
   ],
   "source": [
    "# [config] HiperparÃ¡metros fijos\n",
    "TARGET_SIZE = (224,224)\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print('Device ->', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe1c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VolÃºmenes encontrados: 279\n",
      "Clases: 0=74, 1=116, pos_weight=0.64\n",
      "Bach 8, slices 20, epocas 20, patience 5\n",
      "\n",
      "=== Entrenando resnet18 ===\n"
     ]
    }
   ],
   "source": [
    "# 1. HiperparÃ¡metros variables\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 20         # Ã‰pocas para entrenar\n",
    "N_SLICES = 20\n",
    "LR = 1e-5\n",
    "PATIENCE = 5\n",
    "main(dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26745170",
   "metadata": {},
   "source": [
    "| Variante                                 |                 LR (init / schedule) | Weight decay | Ã‰pocas | Slices | Patience | Loss / balance                           |              Batch | ObservaciÃ³n / objetivo                                                                                                   | Prioridad |\n",
    "| ---------------------------------------- | -----------------------------------: | -----------: | -----: | -----: | -------: | ---------------------------------------- | -----------------: | ------------------------------------------------------------------------------------------------------------------------ | --------: |\n",
    "| **Base (control)**                       |                             **1e-5** |     **1e-5** |     20 |     20 |        5 | BCEWithLogits + pos_weight=0.64          |                  8 | Punto de partida (tu mejor hasta ahora). Verificar reproducibilidad.                                                     |   ðŸ”· Alta |\n",
    "| **V1 â€” LR subida leve**                  |                                 3e-5 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | LR un poco mayor para acelerar convergencia sin desestabilizar. Good first test.                                         |   ðŸ”· Alta |\n",
    "| **V2 â€” LR mÃ¡s alto (exploratorio)**      |                                 1e-4 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | Prueba el LR que preguntaste; detecta si entrenar mÃ¡s rÃ¡pido ayuda o provoca inestabilidad.                              |  ðŸ”¶ Media |\n",
    "| **V3 â€” MÃ¡s regularizaciÃ³n + mÃ¡s Ã©pocas** |                                 1e-5 |     **1e-4** | **30** |     20 |        5 | BCEWithLogits + pos_weight (o Focal Î³=2) |                  8 | Aumentar WD para combatir overfitting al extender entrenamiento; probar Focal si hay ejemplos difÃ­ciles.                 |   ðŸ”· Alta |\n",
    "| **V4 â€” MÃ¡s contexto espacial**           |                                 1e-5 |         1e-5 |     30 | **30** |        5 | BCEWithLogits + pos_weight               | 8 (o 4 si memoria) | Aumentar slices a 30 (si lo soporta GPU) para mejorar seÃ±ales 3D; mÃ¡s Ã©pocas para aprovecharlo.                          |  ðŸ”¶ Media |\n",
    "| **V5 â€” Scheduler / OneCycle**            | base_lr=1e-5, max_lr=1e-4 (OneCycle) |         1e-5 |     30 |     20 |        5 | BCEWithLogits + pos_weight (o Focal)     |                  8 | Uso de OneCycle (o cosine) para combinar estabilidad inicial y picos de LR: suele dar buen rendimiento sin mucha tuning. |   ðŸ”· Alta |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
